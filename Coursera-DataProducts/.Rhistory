folds$train[1]
install.packages("ISLR")
library(ISLR); library(ggplot2), library(caret)
library(ISLR); library(ggplot2); library(caret)
data(Wage)
summary(Wage)
pair(Wage)
inTrain <- createDataPartition(y=Wage$wage, p=.7, list=FALSE)
training <- Wage[inTrain,]
testing <- Wage[-inTrain,]
dim(training); dim(testing)
featurePlot(x=training[,c('age', 'education', 'jobclass')],)
featurePlot(x=training[,c('age', 'education', 'jobclass')], y=training$wage, plot="pairs")
qplot(age, wage, data=training)
qplot(age, wage, colour=jobclass, data=training)
qq <- qplot(age, wage, colour=education, data=training)
qq+ geom_smooth(method='lm', formula=y~x)
install.package('Hmisc')
install.packages('Hmisc')
cutWage <- cut2(training$wage, g=3)
required('Hmisc')
require('Hmisc')
cutWage <- cut2(training$wage, g=3)
table(cutWage)
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
install.packages('AppliedPredictiveModeling')
data(AlzheimerDisease)
data(AlzheimerDisease)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
head(AlzheimerDiesease)
head(AlzheimerDisease)
data(AlzheimerDisease)
AlzheimerDisease
diagnosis
predictors
data(AlzheimerDisease) -> a
a
predictors
head(predictors)
summary(predictors)
adData = data.frame(predictors)
adData = data.frame(diagnosis,predictors)
head(adData)
head(diagnosis)
data(concrete)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p=3/4)[[1]]
training = mixtures[inTrain,]
testing=mixtures[-inTrain,]
dim(inTrain,)
dim(training, testing)
dim(training)
dim(testing)
mixtures
head(mixtures)
head(mixtures$CompressiveStrength)
dim(mixtures)
dim(training, testing)
dim(training)
head(training)
qplot(CompressiveStrength, color=Age, data=training)
qplot(CompressiveStrength, colour=Age, data=training)
qplot(CompressiveStrength, Water, colour=Age, data=training)
str(training)
featurePlot(x=training[,colnames], y=training$CompressiveStrength, plot='pairs')
featurePlot(x=training, y=training$CompressiveStrength, plot='pairs')
index = seq_along(1:nrow(training))
ggplot(data=training, aes(x=index, y=CompressiveStrength)) + geom_point()
ggplot(data=training, aes(x=index, y=CompressiveStrength)) + geom_point(aes(fill=FlyAsh))
ggplot(data=training, aes(x=index, y=CompressiveStrength)) + geom_point(aes(fill=Age))
ggplot(data=training, aes(x=index, y=CompressiveStrength)) + geom_point(aes(fill=Age), colour='blue')
ggplot(data=training, aes(x=index, y=CompressiveStrength)) + geom_point(aes(fill=FineAggregate))
ggplot(data=training, aes(x=index, y=CompressiveStrength)) + geom_point(aes(fill=CourseAggregate))
ggplot(data=training, aes(x=Superplasticizer)) + geom_histogram()
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
colnames(training)
?preProcess
IL_cols <- grep("^IL", colnames(training), value=TRUE)
IL_cols
pre <- preProcess(training[,IL_cols], method='pca', thresh=.8)
summary(pre)
pre$rotation
summary(pre)
summary(prcomp(training))
summary(training)
colnames(pre)
preProc <- preProcess(training[, IL_str], method = "pca", thresh = 0.8)
preProc <- preProcess(training[, IL_cols], method = "pca", thresh = 0.8)
?PreProcess
pre1 <- preProcess(training[, IL_cols], method = c('center','scale'))
pre2 <- predict(pre1, training[,IL_cols])
pre2
summary(pre2)
sumary(prcomp(pre2))
summary(prcomp(pre2))
predictors_IL <- predictors[,IL_cols]
df = data.frame(diagnosis, predictors_IL)
inTrain = createDataPartition(df$diagnosis, p=3/4)[[1]]
training=df[inTrain,]
testing]=df[inTrain,]
testing=df[inTrain,]
testing=df[-inTrain,]
modelFit <- train(diagnosis ~., method='glm', data=training)
predictions <- predict(modelFit, newdata = testing)
C1 <- confusionMatrix(predictions, testing$diagnosis)
print(C1)
modelFit2 <- train(training$diagnosis ~ ., method = "glm", preProcess = "pca",
data = training, trControl = trainControl(preProcOptions = list(thresh = 0.8)))
C2 <- confusionMatrix(testing$diagnosis, predict(modelFit2, testing))
print(C2)
?rm
rm(list=ls())
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
names(segmentationOriginal)
head(segmentationOriginal$Case)
?segmentationOriginal
head(segmentationOriginal$Class)
inTrain <- createDataPartition(y=segmentationOriginal$Class, p=0.7, list=FALSE)
train <- segmentationOriginal[inTrain,]
test <- segmentationOriginal[-inTrain,]
colnames(train)
?FeaturePlot
??FeaturePlot
set.see(125)
set.seed(125)
?train
modelFit <- train(data ~., method='rpart', data=train)
modelFit <- train(train ~., method='rpart', data=train)
training <- segmentationOriginal[inTrain,]
testing <- segmentationOriginal[-inTrain,]
rpartFit <- train(training ~., method='rpart', data=training)
rpartFit <- train(Class ~., method='rpart', data=training)
?predict
summary(rpartFit)
predictions <- predict(rpartFit, newdata=testing)
summmary(predictions)
summary(predictions)
plot(rpartFit$finalModel, uniform=TRUE, main="Classification Tree")
test(rpartFit$finalModel, use.n=TRUE, all=TRUE, cex=.8)
text(rpartFit$finalModel, use.n=TRUE, all=TRUE, cex=.8)
library(rattle)
install.packages('rattle')
library(rattle)
fancyRpartPlot(rpartFit$finalModel)
fancyRpartPlot(rpartFit$finalModel)
?rattle
?fancyRpartPlot
fancyRpartPlot(rpartFit$finalModel)
fancyRpartPlot(rpartFit$finalModel)
plot(rpartFit$finalModel, uniform=TRUE, main="Classification Tree")
text(rpartFit$finalModel, use.n=TRUE, all=TRUE, cex=.8)
print(rpartFit$finalModel)
rm(list=ls())
library(pgmm)
install.packages('pgmm')
data(olive)
data(olive)
data('olive')
require(pgmm)
data(olive)
olive=olive[,-1]
data(olive)
head(olive)
olive = olive[,-1]
head(olive)
inTrain = createDataPartition(olive$Area,p=.7, list=FALSE)
training <- olive[inTrain,]
testing <- olive[-inTrain,]
train(Area ~., method='rpart', data=training)
treeModel <- train(Area ~., method='rpart', data=training)
print(treeModel)
newdata = as.data.frame(t(colMeans(olive)))
predict(treeModel,newdata)
library(tree)
install.packages('tree')
require(tree)
treeModel <- train(Area ~., method='rpart', data=olive)
predict(treeModel,newdata)
rm(list=ls())
library(ElemStatLearn)
install.packages(ElemStatLearn)
install.packages('ElemStatLearn')
library(ElemStatLearn)
data(SAheart)
train = sample(1:dim(SAheart))[1]
train = sample(1:dim(SAheart))[1],size=dim(SAheart)[1]/2,replace=F)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
?train
colnames(SAheart)
lFit <- train(chd ~ age + alcohool + obesity + tobacco + typea + ldl, method='glm', family='binomial')
lFit <- train(chd ~ age + alcohool + obesity + tobacco + typea + ldl, method='glm', family='binomial' data=trainSA)
lFit <- train(chd ~ age + alcohool + obesity + tobacco + typea + ldl, method='glm', family='binomial', data=trainSA)
lFit <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl, method='glm', family='binomial', data=trainSA)
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass
missClass(testSA$chd, predTest)
predTest <- predict(lFit, testing)
predTest <- predict(lFit, testSA)
missClass(testSA$chd, predTest)
predTest2 <- predict(lFit, trainSA)
missClass(testSA$chd, predTest2)
data(vowel.train)
data(vowel.test)
set.seed(33833)
colnames(vowel.train)
colnames(vowel.test)
head(vowel.train)
str(vowel.train)
rfFit <- train(y ~ ., data=vowel.train, method='rf', prox=TRUE)
rfFit <- train(y ~ ., data=vowel.train, method='rf', prox=TRUE)
?varImp
varImp(rfFit)
varImp(rfFit, scale=TRUE)
varImp(rfFit)
?train
rfFit <- train(y ~ ., data=vowel.train, method='rf', importance=TRUE)
varImp(rfFit, type=2)
varImp(rfFit)
?varImp
varImp(rfFit, type=2)
varImp(rfFit, scale=2)
varImp(rfFit, value=2)
varImp(rfFit, value=2, scale=FALSE)
predTest <- predict(rfFit, vowel.test)
varImp(PredTest, value=2)
varImp(predTest, value=2)
varImp(predTest)
summary(predTest)
?importance
importance(rfFit)
importance(rfFit, type=2)
vowel.rf <- randomForest(y ~., data=vowel.train, importance=TRUE)
importance(vowel.rf)
importance(vowel.rf, type=2)
importance(vowel.rf, type=2, order=TRUE)
rm=(list=ls())
#Read in data from Coursera Links, do not need to uncompress when reading bz2 files
download.file('https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2', 'storm.csv', method='curl',mode="wb")
storm = read.csv('storm.csv')
colnames(storm)
unique(evtype)
unique(storm$EVTYPE)
unique(storm$PROPMGEXP)
range(storm$PROPDMG)
unique(storm$PROPDMGEXP)
range(storm$CROPDMG)
unique(storm$CROPDMGEXP)
ggplot(storm, aes(x=INJURIES, y=FATALITIES, colour=EVTYPE)) + geom_point()
require(ggplot)
require(ggplot2)
ggplot(storm, aes(x=INJURIES, y=FATALITIES, colour=EVTYPE)) + geom_point()
unique(EVTYPE)
unique(storm$EVTYPE)
library(dplyr)
?group_by
?aggregate
storm_popharm = group_by(.storm, EVTYPE)
storm_popharm = group_by(storm, EVTYPE)
storm_popharm2 = summarise(storm_popharm, T_FATALITIES = sum(FATALITIES), T_INJURIES = sum(INJURIES))
?summarise
?arrange
dfFatality <- aggregate(FATALITIES ~ EVTYPE, dfStorm, sum)
dfFatality <- head(dfFatality[order(dfFatality$FATALITIES,
decreasing=TRUE),], 10)
dfFatality <- aggregate(FATALITIES ~ EVTYPE, storm, sum)
dfFatality <- head(dfFatality[order(dfFatality$FATALITIES,
decreasing=TRUE),], 10)
plot1 <- ggplot(dfFatality, aes(x=reorder(EVTYPE,FATALITIES), y=FATALITIES)) +
geom_bar(stat="identity") + coord_flip() +
labs(x="Weather Event Type", y="No. of Fatalities") +
ggtitle("Top 10 Events Harmful to Population Health (Fatalities)")
plot1
Fatality <- aggregate(FATALITIES ~ EVTYPE, storm, sum)
Fatality <- head(dfFatality[order(dfFatality$FATALITIES,
decreasing=TRUE),], 10)
plot1 <- ggplot(Fatality, aes(x=reorder(EVTYPE,FATALITIES), y=FATALITIES)) +
geom_bar(stat="identity") +
labs(x="Storm Event Type", y="Number of Fatalities") +
ggtitle("Top 10 Storm Events By Fatalities Rates")
plot1 <- ggplot(Fatality, aes(x=reorder(EVTYPE,FATALITIES), y=FATALITIES)) +
geom_bar(stat="identity") +
labs(x="Storm Event Type", y="Number of Fatalities") +
ggtitle("Top 10 Storm Events By Fatalities Rates")
plot1 <- ggplot(Fatality, aes(x=reorder(EVTYPE,FATALITIES), y=FATALITIES)) +
geom_bar(stat="identity") +
labs(x="Storm Event Type", y="Number of Fatalities") +
ggtitle("Top 10 Storm Events By Fatalities Rates")
plot1
plot1 <- ggplot(Fatality, aes(x=EVTYPE, y=FATALITIES)) +
geom_bar(stat="identity") + coord_flip()
labs(x="Storm Event Type", y="Number of Fatalities") +
ggtitle("Top 10 Storm Events By Fatalities Rates")
plot1 <- ggplot(Fatality, aes(x=EVTYPE, y=FATALITIES)) +
geom_bar(stat="identity") + coord_flip() +
labs(x="Storm Event Type", y="Number of Fatalities") +
ggtitle("Top 10 Storm Events By Fatalities Rates")
plot1
?ggplot
plot1 <- ggplot(Fatality, aes(x=reorder(EVTYPE, FATALITIES), y=FATALITIES)) +
geom_bar(stat="identity") + coord_flip() +
labs(x="Storm Event Type", y="Number of Fatalities") +
ggtitle("Top 10 Storm Events By Fatalities Rates")
plot1
colnames(storm)
Injury <- aggregate(INJURIES ~ EVTYPE, storm, sum)
Injury <- head(Injury[order(Injury$INJURIES,
decreasing=TRUE),], 10)
plot1 <- ggplot(Injury, aes(x=reorder(EVTYPE, INJURIES), y=INJURIES)) +
geom_bar(stat="identity") + coord_flip() +
labs(x="Storm Event Type", y="Number of Injuries") +
ggtitle("Top 10 Storm Events By Injury Rates")
plot2 <- ggplot(Injury, aes(x=reorder(EVTYPE, INJURIES), y=INJURIES)) +
geom_bar(stat="identity") + coord_flip() +
labs(x="Storm Event Type", y="Number of Injuries") +
ggtitle("Top 10 Storm Events By Injury Rates")
plot1 <- ggplot(Fatality, aes(x=reorder(EVTYPE, FATALITIES), y=FATALITIES)) +
geom_bar(stat="identity") + coord_flip() +
labs(x="Storm Event Type", y="Number of Fatalities") +
ggtitle("Top 10 Storm Events By Fatalities Rates")
multiplot(plot1, plot2, cols=2)
library(ggplot2)
multiplot(plot1, plot2, cols=2)
multiplot(plot1, plot2)
multiplot?
?
P
?multiplot
??multiplot
par(mfrow = c(2,1))
plot 1
grid.arrange(plot1, plot2, ncol=2, main='Top 10 Population Harm by Event Types')
grid.arrange(plot1, plot2, ncol=2, main='Top 10 Population Harm by Event Types')
library(ggplot2)
library(dplyr)
library(grid)
library(gridExtra)
grid.arrange(plot1, plot2, ncol=2, main='Top 10 Population Harm by Event Types')
grid.arrange(plot1, plot2, ncol=1, main='Top 10 Population Harm by Event Types')
library(car)
Storm$Calc_PropDmg <- dfStorm$PROPDMG * Recode(Storm$PROPDMGEXP,
"'0'=10^0; '1'=10^1; '2'=10^2; '3'=10^3; '4'=10^4; '5'=10^5;
'6'=10^6; '7'=10^7; '8'=10^8; 'h'=10^2; 'H'=10^2;
'K'=10^3; 'm'=10^6; 'M'=10^6; 'B'=10^9; else=0",as.factor.result=FALSE)
#use the car package/RECODE to calculate the total damage amount = crop damange * crop
storm$Calc_PropDmg <- storm$PROPDMG * Recode(storm$PROPDMGEXP,
"'0'=10^0; '1'=10^1; '2'=10^2; '3'=10^3; '4'=10^4; '5'=10^5;
'6'=10^6; '7'=10^7; '8'=10^8; 'h'=10^2; 'H'=10^2;
'K'=10^3; 'm'=10^6; 'M'=10^6; 'B'=10^9; else=0",as.factor.result=FALSE)
storm$Calc_CropDmg <- storm$CROPDMG * Recode(storm$CROPDMGEXP,
"'0'=1; '2'=10^2; 'k'=10^3; 'K'=10^3; 'm'=10^6; 'M'=10^6;
'B'=10^9; else=0", as.factor.result=FALSE)
colnames(storm)
range(Calc_PropDmg)
range(storm$Calc_PropDmg)
range(Calc_CropDmg)
range(storm$Calc_PropDmg)
range(storm$Calc_CropDmg)
PropDmg <- aggregate(Calc_PropDmg ~ EVTYPE, storm, sum)
PropDmg <- head(PropDmg[order(PropDmg$PropDmg,
decreasing=TRUE),], 10)
PropDmg
Fatalities
Fatality
head(PropDmg)
?recode
storm$Calc_PropDmg <- storm$PROPDMG * recode(storm$PROPDMGEXP,
"'0'=10^0; '1'=10^1; '2'=10^2; '3'=10^3; '4'=10^4; '5'=10^5;
'6'=10^6; '7'=10^7; '8'=10^8; 'h'=10^2; 'H'=10^2;
'K'=10^3; 'm'=10^6; 'M'=10^6; 'B'=10^9; else=0",as.factor.result=FALSE)
storm$Calc_CropDmg <- storm$CROPDMG * recode(storm$CROPDMGEXP,
"'0'=1; '2'=10^2; 'k'=10^3; 'K'=10^3; 'm'=10^6; 'M'=10^6;
'B'=10^9; else=0", as.factor.result=FALSE)
PropDmg <- head(PropDmg[order(PropDmg$PropDmg,
decreasing=TRUE),], 10)
type(PropDmg)
typeof(PropDmg)
type(Fatalities)
typeof(Fatalities)
typeof(Fatality)
PropDmg$PropDmg
PropDmg <- aggregate(Calc_PropDmg ~ EVTYPE, storm, sum)
PropDmg <- head(PropDmg[order(PropDmg$PropDmg,
decreasing=TRUE),], 10)
PropDmg$PropDmg
colnames(PropDmg)
PropDmg <- head(PropDmg[order(PropDmg$Calc_PropDmg,
decreasing=TRUE),], 10)
plot3 <- ggplot(PropDmg, aes(x=reorder(EVTYPE, Calc_PropDmg), y=Calc_PropDmg)) +
geom_bar(stat="identity") + coord_flip() +
labs(x="Storm Event Type", y="Property Damage ($)") +
ggtitle("Top 10 Storm Events By Total Property Damage")
library(ggplot2)
library(ggplot2)
plot3 <- ggplot(PropDmg, aes(x=reorder(EVTYPE, Calc_PropDmg), y=Calc_PropDmg)) +
geom_bar(stat="identity") + coord_flip() +
labs(x="Storm Event Type", y="Property Damage ($)") +
ggtitle("Top 10 Storm Events By Total Property Damage")
plot3
CropDmg <- aggregate(Calc_CropDmg ~ EVTYPE, storm, sum)
CropDmg <- head(CropDmg[order(CropDmg$Calc_CropDmg,
decreasing=TRUE),], 10)
plot4 <- ggplot(CropDmg, aes(x=reorder(EVTYPE, Calc_CropDmg), y=Calc_CropDmg)) +
geom_bar(stat="identity") + coord_flip() +
labs(x="Storm Event Type", y="Crop Damage ($)") +
ggtitle("Top 10 Storm Events By Total Crop Damage")
grid.arrange(plot3, plot4, ncol=1, main='Top 10 Economic Harms by Event Types')
library(dplyr)
library(grid)
library(gridExtra)
grid.arrange(plot3, plot4, ncol=1, main='Top 10 Economic Harms by Event Types')
storm$Calc_PropDmg <- storm$PROPDMG * recode(storm$PROPDMGEXP,
"'0'=10^0; '1'=10^1; '2'=10^2; '3'=10^3; '4'=10^4; '5'=10^5;
'6'=10^6; '7'=10^7; '8'=10^8; 'h'=10^2; 'H'=10^2;
'K'=10^3; 'm'=10^6; 'M'=10^6; 'B'=10^9; else=0",as.factor.result=FALSE)
?recode
install.packages('shiny')
library(shiny)
shiny::runApp('Coursera-DataProducts/App-FashionOnTwitter')
getwd()
setwd('.Coursera-DataProducts/App-FashionOnTwitter')
setwd('./Coursera-DataProducts/App-FashionOnTwitter')
getwd()
brand
rm=(list=ls())
rm(list=ls())
data.frame(read.csv('@WhoWhatWear _final_val.csv'))
data.frame(read.csv('@WhoWhatWear _final_val.csv', header=TRUE))
setwd('./data')
data.frame(read.csv('@WhoWhatWear _final_val.csv', header=TRUE))
brand = data.frame(read.csv('@WhoWhatWear _final_val.csv', header=TRUE))
summary(brand)
View(brand)
ggplot(brand, aes(ymd_hms(time), score)) + geom_point() +
stat_summary(fun.data = 'mean_cl_normal', mult = 1, geom = 'smooth') +
ggtitle(paste(input$data, as.Date(brand$created))) + scale_y_continuous(limits=c(1, 9), breaks=c(1:9))
ggplot(brand, aes(ymd_hms(time), score)) + geom_point() +
stat_summary(fun.data = 'mean_cl_normal', mult = 1, geom = 'smooth') +
ggtitle(paste(input$data, as.Date(brand$created)))
View(brand)
ggplot(brand, aes(ymd_hms(time), score)) + geom_point() +
stat_summary(fun.data = 'mean_cl_normal', mult = 1, geom = 'smooth') +
ggtitle(paste('@WhoWhatWear', as.Date(brand$created)))
shiny::runApp('~/data_science/Coursera-DataProducts/App-FashionOnTwitter')
shiny::runApp('~/data_science/Coursera-DataProducts/App-FashionOnTwitter')
shiny::runApp('~/data_science/Coursera-DataProducts/App-FashionOnTwitter')
shiny::runApp('~/data_science/Coursera-DataProducts/App-FashionOnTwitter')
shiny::runApp('~/data_science/Coursera-DataProducts/App-FashionOnTwitter')
sapply(brand, function(x) sum(is.na(x)))
?stat_summary
shiny::runApp('~/data_science/Coursera-DataProducts/App-FashionOnTwitter')
shiny::runApp('~/data_science/Coursera-DataProducts/App-FashionOnTwitter')
shiny::runApp('~/data_science/Coursera-DataProducts/App-FashionOnTwitter')
shiny::runApp('~/data_science/Coursera-DataProducts/App-FashionOnTwitter')
shiny::runApp('~/data_science/Coursera-DataProducts/App-FashionOnTwitter')
shiny::runApp('~/data_science/Coursera-DataProducts/App-FashionOnTwitter')
shiny::runApp('~/data_science/Coursera-DataProducts/App-FashionOnTwitter')
summary(brand)
shiny::runApp('~/data_science/Coursera-DataProducts/App-FashionOnTwitter')
source(twitter-fashion-sentiment2.R)
getwd()
setwd('..')
getwd()
setwd('..')
getwd()
source(twitter-fashion-sentiment2.R)
source(twitter-fashion-sentiment2.R)
source('twitter-fashion-sentiment2.R')
source('twitter-fashion-sentiment2.R')
source('twitter-fashion-sentiment2.R')
source('twitter-fashion-sentiment2.R')
install.packages('devtools')
devtools::install_github('rstudio/shinyapps')
shinyapps::setAccountInfo(name='powchow',
token='7C511FFBB3B2FD4050E168B6E125B1E1',
secret='<shinyapps::setAccountInfo(name='powchow', token='7C511FFBB3B2FD4050E168B6E125B1E1', secret='HRVa6HavFXV29t/TRuFNBYGs0MMDFEoN9j8z4oTQ')>')
shinyapps::setAccountInfo(name='powchow',
token='7C511FFBB3B2FD4050E168B6E125B1E1',
secret='<shinyapps::setAccountInfo(name='powchow', token='7C511FFBB3B2FD4050E168B6E125B1E1', secret='HRVa6HavFXV29t/TRuFNBYGs0MMDFEoN9j8z4oTQ'>)
shinyapps::setAccountInfo(name='powchow',
token='7C511FFBB3B2FD4050E168B6E125B1E1',
secret='HRVa6HavFXV29t/TRuFNBYGs0MMDFEoN9j8z4oTQ')
library(shinyapps)
getwd()
shinyapps::deployApp('/Users/powchow/data_science/Coursera-DataProducts/App-FashionOnTwitter')
shinyapps::deployApp('/Users/powchow/data_science/Coursera-DataProducts/App-FashionOnTwitter')
shinyapps::deployApp('/Users/powchow/data_science/Coursera-DataProducts/App-FashionOnTwitter')
shinyapps::deployApp('/Users/powchow/data_science/Coursera-DataProducts/App-FashionOnTwitter')
shinyapps::deployApp('/Users/powchow/data_science/Coursera-DataProducts/App-FashionOnTwitter')
library(Hmisc)
shinyapps::deployApp('/Users/powchow/data_science/Coursera-DataProducts/App-FashionOnTwitter')
getwd()
source('twitter-fashion-sentiment2.R')
source('twitter-fashion-sentiment2.R')
source('twitter-fashion-sentiment2.R')
source('twitter-fashion-sentiment2.R')
source('twitter-fashion-sentiment2.R')
source('twitter-fashion-sentiment2.R')
